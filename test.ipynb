{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-20 20:21:32.435039: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2022-06-20 20:21:32.435074: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/root/anaconda3/envs/acmmm/lib/python3.7/site-packages/transformers/models/auto/modeling_auto.py:973: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at binwang/bert-base-nli-stsb and are newly initialized: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device\n",
      "cuda\n",
      "cuda\n",
      "Loading CLIP Model...\n"
     ]
    }
   ],
   "source": [
    "# TODO: COSMOS, OFA, SBERT, NLI, CLIP device\n",
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sbert import sbert\n",
    "from online_search import retrieve\n",
    "tqdm.pandas()\n",
    "folder_contain_test_json = '/root/thesis/dataset/cosmos_anns_acm/acm_anns'\n",
    "folder_contain_image = '/root/thesis/dataset'\n",
    "\n",
    "test_data = list(\n",
    "    map(json.loads, open(os.path.join(folder_contain_test_json,'test_data.json')).readlines())\n",
    ")\n",
    "df = pd.DataFrame(test_data)\n",
    "df['bert_base_score'] = df['bert_base_score'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_div():\n",
    "    term_size = os.get_terminal_size()\n",
    "    print('=' * term_size.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COSMOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:fvcore.common.checkpoint:The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/root/thesis/acmmmcheapfakes/COSMOS')\n",
    "from COSMOS import evaluate_ooc\n",
    "\n",
    "evaluate_ooc.DATA_DIR = folder_contain_image\n",
    "evaluate_ooc.JSON_DIR = folder_contain_test_json\n",
    "\n",
    "evaluate_ooc.main(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.eval_utils' from '/root/thesis/acmmmcheapfakes/COSMOS/utils/eval_utils.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.modules.pop('utils')\n",
    "sys.modules.pop('utils.eval_utils')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/root/thesis/acmmmcheapfakes/OFA')\n",
    "sys.path.remove('/root/thesis/acmmmcheapfakes/COSMOS')\n",
    "sys.path.append('/root/thesis/acmmmcheapfakes/OFA')\n",
    "\n",
    "from OFA.main import run\n",
    "run(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmos_iou = pd.read_csv('pred_contexts.txt', header=None)\n",
    "cosmos_iou.columns = ['iou']\n",
    "df = pd.concat([df, cosmos_iou['iou']], axis=1)\n",
    "\n",
    "ofa_result = pd.read_csv('ofa_full.csv')\n",
    "df = pd.concat([df, ofa_result[['c1_entail','c2_entail']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/root/thesis/acmmmcheapfakes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\", model = \"microsoft/deberta-xlarge-mnli\",\n",
    "device=torch.device('cuda',0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1000 [00:00<01:28, 11.18it/s]/root/anaconda3/envs/acmmm/lib/python3.7/site-packages/transformers/pipelines/base.py:1015: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n",
      "100%|██████████| 1000/1000 [01:26<00:00, 11.58it/s]\n",
      "100%|██████████| 1000/1000 [01:25<00:00, 11.75it/s]\n"
     ]
    }
   ],
   "source": [
    "df['nli_label'] = df.progress_apply(lambda x: classifier(x.caption1+x.caption2)[0], axis=1)\n",
    "df['nli_label_reverse'] = df.progress_apply(lambda x: classifier(x.caption2+x.caption1)[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 15291.49it/s]\n"
     ]
    }
   ],
   "source": [
    "def nli(x):\n",
    "    if (x.nli_label['label'] == 'CONTRADICTION' and x.nli_label_reverse['label'] == 'CONTRADICTION'):\n",
    "        return 'CONTRADICTION'\n",
    "    if (x.nli_label['label'] == 'ENTAILMENT' or x.nli_label_reverse['label'] == 'ENTAILMENT'):\n",
    "        if (x.nli_label['label'] != 'CONTRADICTION' and x.nli_label_reverse['label'] != 'CONTRADICTION'):\n",
    "            return 'ENTAILMENT' \n",
    "    return 'NEUTRAL'\n",
    "df['nli'] = df.progress_apply(lambda x:nli(x), axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:23<00:00, 42.44it/s]\n",
      "100%|██████████| 1000/1000 [00:23<00:00, 41.94it/s]\n",
      "100%|██████████| 1000/1000 [00:24<00:00, 41.60it/s]\n"
     ]
    }
   ],
   "source": [
    "keywords = \"fake, hoax, fabrication, supposedly, falsification, propaganda, deflection, deception, contradicted, defamation, lie, misleading, deceive, fraud, concocted, bluffing, made up, double meaning, alternative facts, trick, half-truth, untruth, falsehoods, inaccurate, disinformation, misconception\"\n",
    "df['cap1_mis']=df.progress_apply(lambda x: sbert([x.caption1_modified,keywords]),axis=1)\n",
    "df['cap2_mis']=df.progress_apply(lambda x: sbert([x.caption2_modified,keywords]),axis=1)\n",
    "\n",
    "def get_fake_scores(row):\n",
    "    new_scores = [0,0,0]\n",
    "    if row['cap1_mis'] > row['cap2_mis'] and row['cap1_mis']>0.15:\n",
    "        c_fake = row['caption2'].rstrip('.') + ' is not genuine.'\n",
    "        new_scores[0] = sbert([c_fake,row['caption1']])\n",
    "\n",
    "        c_fake = row['caption2'].rstrip('.') + ' is fake.'\n",
    "        new_scores[1] = sbert([c_fake,row['caption1']])\n",
    "\n",
    "        c_fake = row['caption2'].rstrip('.') + ' wasn\\'t true.'\n",
    "        new_scores[2] = sbert([c_fake,row['caption1']])\n",
    "    elif row['cap1_mis'] < row['cap2_mis'] and row['cap2_mis']>0.15: \n",
    "        c_fake = row['caption1'].rstrip('.') + ' is not genuine.'\n",
    "        new_scores[0] = sbert([c_fake,row['caption2']])\n",
    "\n",
    "        c_fake = row['caption1'].rstrip('.') + ' is fake.'\n",
    "        new_scores[1] = sbert([c_fake,row['caption2']])\n",
    "\n",
    "        c_fake = row['caption1'].rstrip('.') + ' wasn\\'t true.'\n",
    "        new_scores[2] = sbert([c_fake,row['caption2']])\n",
    "    return new_scores\n",
    "df['false_scores'] = df.progress_apply(lambda x: get_fake_scores(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_everything_online(row):\n",
    "    if row.nli == 'CONTRADICTION':\n",
    "        return (True,'NLI')\n",
    "    if row.nli == 'ENTAILMENT':\n",
    "        return (False,'NLI')\n",
    "    false_scores = row['false_scores']\n",
    "    if np.any(np.array(false_scores) >  row['bert_base_score']+0.05):\n",
    "        return (True, 'MIS')\n",
    "    if row['iou']>0.25:\n",
    "        if row['bert_base_score']<0.5:\n",
    "            c1 = retrieve(os.path.join(folder_contain_image,row['img_local_path']),row['caption1'])[0]\n",
    "            c2 = retrieve(os.path.join(folder_contain_image,row['img_local_path']),row['caption2'])[0]\n",
    "            c1 = c1 > 0.97\n",
    "            c2 = c2 > 0.97\n",
    "            \n",
    "            if c1 and c2:\n",
    "                return (False, 'ONL')\n",
    "\n",
    "            if (c1):\n",
    "                if row['c2_entail']>0.25:\n",
    "                    return (False, 'MAT')\n",
    "            if (c2):\n",
    "                if row['c1_entail']>0.25:\n",
    "                    return (False, 'MAT')\n",
    "\n",
    "            return (True, 'BERT')\n",
    "        return (False, 'BERT')\n",
    "    return (False,'COSMOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df, func):\n",
    "    df['result'] =  df.progress_apply(lambda x:func(x), axis=1)\n",
    "    df['predict'] =  df['result'].apply(lambda x:x[0])\n",
    "    df['method'] =  df['result'].apply(lambda x:x[1])\n",
    "    confusion_matrix = pd.crosstab(df['predict'], df['context_label'], rownames=['Predicted'], colnames=['Actual'])\n",
    "    print(confusion_matrix)\n",
    "    result = (confusion_matrix[0][0]+confusion_matrix[1][1])/len(df)\n",
    "    print('Accuracy:', result)\n",
    "    method_acc = df.groupby('method').apply(lambda g: \\\n",
    "        ((g['context_label']==g['predict']).sum() / len(g),len(g) ))\n",
    "    print(method_acc.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:05<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual      0   1\n",
      "Predicted        \n",
      "False      17   0\n",
      "True        3  10\n",
      "Accuracy: 0.9\n",
      "method\n",
      "BERT      (0.8333333333333334, 12)\n",
      "COSMOS                    (1.0, 4)\n",
      "MIS                      (0.75, 4)\n",
      "NLI                       (1.0, 9)\n",
      "ONL                       (1.0, 1)\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/root/anaconda3/envs/acmmm/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/root/anaconda3/envs/acmmm/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/root/anaconda3/envs/acmmm/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "evaluate(df, predict_everything_online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/acmmm/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predict'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_385023/2468638485.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/acmmm/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/acmmm/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'predict'"
     ]
    }
   ],
   "source": [
    "df.to_csv('result_df.csv', index=False)\n",
    "df['predict'].to_csv('predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f76f71a78fab5ee1ae4e99c64e63a598df0224e97c0b2994533c1132799d43d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('acmmm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f76f71a78fab5ee1ae4e99c64e63a598df0224e97c0b2994533c1132799d43d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
